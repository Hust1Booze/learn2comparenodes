{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1135eb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/data/conda_envs/envs/l2sn/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_104654/3729789995.py\", line 3, in <module>\n",
      "    import torch\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/torch/__init__.py\", line 629, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/torch/functional.py\", line 6, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 2, in <module>\n",
      "    from .linear import Identity, Linear, Bilinear, LazyLinear\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 6, in <module>\n",
      "    from .. import functional as F\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/torch/nn/functional.py\", line 11, in <module>\n",
      "    from .._jit_internal import boolean_dispatch, _overload, BroadcastingList1, BroadcastingList2, BroadcastingList3\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/torch/_jit_internal.py\", line 26, in <module>\n",
      "    import torch.package._mangling as package_mangling\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/torch/package/__init__.py\", line 12, in <module>\n",
      "    from .package_importer import PackageImporter\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/torch/package/package_importer.py\", line 26, in <module>\n",
      "    from ._mock_zipreader import MockZipReader\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/torch/package/_mock_zipreader.py\", line 17, in <module>\n",
      "    _dtype_to_storage = {data_type(0).dtype: data_type for data_type in _storages}\n",
      "  File \"/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/torch/package/_mock_zipreader.py\", line 17, in <dictcomp>\n",
      "    _dtype_to_storage = {data_type(0).dtype: data_type for data_type in _storages}\n",
      "/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/torch/package/_mock_zipreader.py:17: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:67.)\n",
      "  _dtype_to_storage = {data_type(0).dtype: data_type for data_type in _storages}\n",
      "/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch_geometric\n",
    "from pathlib import Path\n",
    "from model import GNNPolicy\n",
    "from data_type import GraphDataset\n",
    "from utils import process\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "982bad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = 'FCMCNF'\n",
    "lr = 0.005\n",
    "n_epoch = 5\n",
    "patience = 10\n",
    "early_stopping = 20\n",
    "normalize = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_train = 1\n",
    "batch_valid  = 256\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer_fn = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b1c3669",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m\n\u001b[1;32m     17\u001b[0m valid_data \u001b[38;5;241m=\u001b[39m GraphDataset(valid_files)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#inspect(train_data[:100])\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# TO DO : learn something from the data\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_geometric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstraint_features_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstraint_features_t\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvariable_features_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvariable_features_t\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m valid_loader \u001b[38;5;241m=\u001b[39m torch_geometric\u001b[38;5;241m.\u001b[39mloader\u001b[38;5;241m.\u001b[39mDataLoader(valid_data, \n\u001b[1;32m     31\u001b[0m                                                  batch_size\u001b[38;5;241m=\u001b[39mbatch_valid, \n\u001b[1;32m     32\u001b[0m                                                  shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m                                                                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_features_s\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     36\u001b[0m                                                                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_features_t\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     38\u001b[0m policy \u001b[38;5;241m=\u001b[39m GNNPolicy()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/torch_geometric/loader/dataloader.py:87\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, follow_batch, exclude_keys, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_batch \u001b[38;5;241m=\u001b[39m follow_batch\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexclude_keys \u001b[38;5;241m=\u001b[39m exclude_keys\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCollater\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/torch/utils/data/dataloader.py:270\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;66;03m# Cannot statically verify that dataset is Sized\u001b[39;00m\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;66;03m# Somewhat related: see NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/data/conda_envs/envs/l2sn/lib/python3.9/site-packages/torch/utils/data/sampler.py:102\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith replacement=False, num_samples should not be specified, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msince a random permute will be performed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue, but got num_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples))\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "\n",
    "train_files = [ str(path) for path in Path(os.path.join(os.path.abspath(''), \n",
    "                                                        f\"../node_selection/data/{problem}/train\")).glob(\"*.pt\") ]\n",
    "\n",
    "valid_files = [ str(path) for path in Path(os.path.join(os.path.abspath(''), \n",
    "                                                        f\"../node_selection/data/{problem}/valid\")).glob(\"*.pt\") ]\n",
    "\n",
    "\n",
    "train_files += valid_files[:7000]\n",
    "valid_files = valid_files[7000:]\n",
    "\n",
    "train_data = GraphDataset(train_files)\n",
    "valid_data = GraphDataset(valid_files)\n",
    "\n",
    "#inspect(train_data[:100])\n",
    "\n",
    "# TO DO : learn something from the data\n",
    "train_loader = torch_geometric.loader.DataLoader(train_data, \n",
    "                                                 batch_size=batch_train, \n",
    "                                                 shuffle=True, \n",
    "                                                 follow_batch=['constraint_features_s', \n",
    "                                                               'constraint_features_t',\n",
    "                                                               'variable_features_s',\n",
    "                                                               'variable_features_t'])\n",
    "\n",
    "valid_loader = torch_geometric.loader.DataLoader(valid_data, \n",
    "                                                 batch_size=batch_valid, \n",
    "                                                 shuffle=False, \n",
    "                                                 follow_batch=['constraint_features_s',\n",
    "                                                               'constraint_features_t',\n",
    "                                                               'variable_features_s',\n",
    "                                                               'variable_features_t'])\n",
    "\n",
    "policy = GNNPolicy().to(device)\n",
    "optimizer = optimizer_fn(policy.parameters(), lr=lr) #ADAM is the best\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(f\"GNN for problem {problem}\")\n",
    "print(f\"Training on:          {len(train_data)} samples\")\n",
    "print(f\"Validating on:        {len(valid_data)} samples\")\n",
    "print(f\"Batch Size Train:     {batch_train}\")\n",
    "print(f\"Batch Size Valid      {batch_valid}\")\n",
    "print(f\"Learning rate:        {lr} \")\n",
    "print(f\"Number of epochs:     {n_epoch}\")\n",
    "print(f\"Normalize:            {normalize}\")\n",
    "print(f\"Device:               {device}\")\n",
    "print(f\"Loss fct:             {loss_fn}\")\n",
    "print(f\"Optimizer:            {optimizer_fn}\")  \n",
    "print(f\"Model's Size:         {sum(p.numel() for p in policy.parameters())} parameters \")\n",
    "print(\"-------------------------\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c79d8a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train loss: 0.072, accuracy 0.953\n",
      "Valid loss: 0.061, accuracy 0.957\n",
      "Epoch 2\n",
      "Train loss: 0.068, accuracy 0.951\n",
      "Valid loss: 0.061, accuracy 0.957\n",
      "Epoch 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_61678/2522883233.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch + 1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     train_loss, train_acc = process(policy, \n\u001b[0m\u001b[1;32m      5\u001b[0m                                     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                     \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local_workspace/labaabde/learn2selectnodes/learning/utils.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(policy, data_loader, loss_fct, device, optimizer, normalize)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;31m#0,1 label from -1,1 label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0my_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/l2sn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local_workspace/labaabde/learn2selectnodes/learning/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch, inv, epsilon)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mgraph0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mscore0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgraph0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#concatenation of averages variable/constraint features after conv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mscore1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgraph1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local_workspace/labaabde/learn2selectnodes/learning/model.py\u001b[0m in \u001b[0;36mforward_graph\u001b[0;34m(self, constraint_features, edge_indices, edge_features, variable_features, bbounds, constraint_batch, variable_batch)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;31m#cons to var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             variable_features = F.relu(conv((constraint_features, variable_features), \n\u001b[0m\u001b[1;32m    161\u001b[0m                                       \u001b[0medge_indices_reversed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                                       \u001b[0medge_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/l2sn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/l2sn/lib/python3.9/site-packages/torch_geometric/nn/conv/graph_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight, size)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# propagate_type: (x: OptPairTensor, edge_weight: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         out = self.propagate(edge_index, x=x, edge_weight=edge_weight,\n\u001b[0m\u001b[1;32m     70\u001b[0m                              size=size)\n\u001b[1;32m     71\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_rel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/l2sn/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                         \u001b[0mmsg_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmsg_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmsg_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/l2sn/lib/python3.9/site-packages/torch_geometric/nn/conv/graph_conv.py\u001b[0m in \u001b[0;36mmessage\u001b[0;34m(self, x_j, edge_weight)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_j\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0medge_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epoch):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "\n",
    "    train_loss, train_acc = process(policy, \n",
    "                                    train_loader, \n",
    "                                    loss_fn,\n",
    "                                    device,\n",
    "                                    optimizer=optimizer, \n",
    "                                    normalize=normalize)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    print(f\"Train loss: {train_loss:0.3f}, accuracy {train_acc:0.3f}\" )\n",
    "\n",
    "    valid_loss, valid_acc = process(policy, \n",
    "                                    valid_loader, \n",
    "                                    loss_fn, \n",
    "                                    device,\n",
    "                                    optimizer=None,\n",
    "                                    normalize=normalize)\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accs.append(valid_acc)\n",
    "\n",
    "    print(f\"Valid loss: {valid_loss:0.3f}, accuracy {valid_acc:0.3f}\" )\n",
    "torch.save(policy.state_dict(),f'policy_{problem}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edd0910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(policy.state_dict(),f'policy_{problem}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a658ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "decisions = [ policy(dvalid.to(device)).item() for dvalid in valid_data ]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(0)\n",
    "plt.hist(decisions)\n",
    "plt.title('decisions histogramme for valid set')\n",
    "plt.savefig(\"./hist.png\")\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(valid_losses, label='valid')\n",
    "plt.title('losses')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.savefig(\"./losses.png\")\n",
    "\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(train_accs, label='train')\n",
    "plt.plot(valid_accs, label='valid')\n",
    "plt.title('accuracies')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.savefig(\"./accuracies.png\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
